#!/bin/bash

# ğŸŒ Virtual Earth Language Evolution - Ubuntuä¸“ç”¨å®Œæ•´é¡¹ç›®è®¾ç½®è„šæœ¬
# é€‚é…Ubuntu 18.04+ / 20.04+ / 22.04+

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

print_header() {
    echo -e "${PURPLE}"
    echo "ğŸŒ=====================================ğŸŒ"
    echo "  Virtual Earth Language Evolution    "
    echo "  Ubuntu Complete Setup Script        "
    echo "ğŸŒ=====================================ğŸŒ"
    echo -e "${NC}"
}

print_status() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_info() {
    echo -e "${BLUE}ğŸ“‹ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

# æ£€æŸ¥Ubuntuç‰ˆæœ¬
check_ubuntu_version() {
    if [[ -f /etc/os-release ]]; then
        . /etc/os-release
        if [[ $ID == "ubuntu" ]]; then
            print_info "æ£€æµ‹åˆ° Ubuntu $VERSION"
            UBUNTU_VERSION=$VERSION_ID
        else
            print_warning "æœªæ£€æµ‹åˆ°Ubuntuç³»ç»Ÿï¼Œç»§ç»­æ‰§è¡Œ..."
        fi
    fi
}

# å®‰è£…ç³»ç»Ÿä¾èµ–
install_system_dependencies() {
    print_info "æ›´æ–°ç³»ç»ŸåŒ…ç´¢å¼•..."
    sudo apt update

    print_info "å®‰è£…ç³»ç»Ÿä¾èµ–åŒ…..."
    sudo apt install -y \
        curl \
        wget \
        git \
        build-essential \
        python3-dev \
        python3-pip \
        python3-venv \
        libssl-dev \
        libffi-dev \
        libbz2-dev \
        libreadline-dev \
        libsqlite3-dev \
        libncurses5-dev \
        libncursesw5-dev \
        xz-utils \
        tk-dev \
        libxml2-dev \
        libxmlsec1-dev \
        libffi-dev \
        liblzma-dev \
        ffmpeg \
        libsm6 \
        libxext6 \
        libxrender-dev \
        libglib2.0-0 \
        libgtk-3-dev \
        tree \
        htop \
        tmux \
        vim

    print_status "ç³»ç»Ÿä¾èµ–å®‰è£…å®Œæˆ"
}

# æ£€æŸ¥å¹¶å®‰è£…Miniconda
install_miniconda() {
    if command -v conda &> /dev/null; then
        print_info "Condaå·²å®‰è£…: $(conda --version)"
    else
        print_info "å®‰è£…Miniconda..."
        
        # æ£€æµ‹ç³»ç»Ÿæ¶æ„
        ARCH=$(uname -m)
        if [[ $ARCH == "x86_64" ]]; then
            MINICONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh"
        elif [[ $ARCH == "aarch64" ]]; then
            MINICONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"
        else
            print_error "ä¸æ”¯æŒçš„ç³»ç»Ÿæ¶æ„: $ARCH"
            exit 1
        fi
        
        wget $MINICONDA_URL -O miniconda.sh
        bash miniconda.sh -b -p $HOME/miniconda3
        rm miniconda.sh
        
        # åˆå§‹åŒ–conda
        $HOME/miniconda3/bin/conda init bash
        export PATH="$HOME/miniconda3/bin:$PATH"
        
        print_status "Minicondaå®‰è£…å®Œæˆ"
        print_warning "è¯·é‡æ–°å¯åŠ¨ç»ˆç«¯æˆ–è¿è¡Œ: source ~/.bashrc"
    fi
}

print_header

# æ£€æŸ¥ç³»ç»Ÿç‰ˆæœ¬
check_ubuntu_version

# 1. å®‰è£…ç³»ç»Ÿä¾èµ–
install_system_dependencies

# 2. å®‰è£…Minicondaï¼ˆå¦‚æœéœ€è¦ï¼‰
read -p "æ˜¯å¦è¦å®‰è£…Miniconda? (æ¨è) [y/N]: " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    install_miniconda
fi

# 3. åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
print_info "åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„..."

# ä¸»è¦ç›®å½•
directories=(
    "src/envs"
    "src/agents" 
    "src/communication"
    "src/objectives"
    "src/training"
    "src/analysis"
    "src/visualization" 
    "src/utils"
    "configs/geography"
    "configs/objectives"
    "experiments"
    "data/raw"
    "data/processed"
    "data/models"
    "data/evaluation"
    "notebooks"
    "web/frontend/src"
    "web/frontend/public"
    "web/backend/api"
    "web/docker"
    "tests"
    "scripts"
    "docs/paper"
    "docs/api"
    "docs/tutorials"
    ".github/workflows"
)

for dir in "${directories[@]}"; do
    mkdir -p "$dir"
done

# åˆ›å»ºæ‰€æœ‰ __init__.py æ–‡ä»¶
find src -type d -exec touch {}/__init__.py \;

print_status "ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ"

# 4. åˆ›å»ºæ ¸å¿ƒé…ç½®æ–‡ä»¶
print_info "åˆ›å»ºé…ç½®æ–‡ä»¶..."

# requirements.txt
cat > requirements.txt << 'EOF'
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.0.0
wandb>=0.12.0
hydra-core>=1.1.0
omegaconf>=2.1.0
gymnasium>=0.26.0
stable-baselines3>=1.6.0
scipy>=1.7.0
scikit-learn>=1.0.0
networkx>=2.6.0
tqdm>=4.62.0
opencv-python>=4.5.0
pillow>=8.3.0
fastapi>=0.68.0
uvicorn>=0.15.0
websockets>=10.0
jupyter>=1.0.0
notebook>=6.4.0
pytest>=6.2.0
pytest-cov>=2.12.0
black>=21.0.0
flake8>=3.9.0
mypy>=0.910
tensorboard>=2.8.0
EOF

# environment.yml - Ubuntuä¼˜åŒ–ç‰ˆæœ¬
cat > environment.yml << 'EOF'
name: virtual-earth
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults
dependencies:
  - python=3.9
  - pytorch>=2.0.0
  - torchvision
  - torchaudio
  - pytorch-cuda=11.8
  - numpy
  - pandas
  - matplotlib
  - seaborn
  - plotly
  - scipy
  - scikit-learn
  - networkx
  - tqdm
  - opencv
  - pillow
  - jupyter
  - notebook
  - tensorboard
  - pip
  - pip:
    - wandb>=0.12.0
    - hydra-core>=1.1.0
    - omegaconf>=2.1.0
    - gymnasium>=0.26.0
    - stable-baselines3>=1.6.0
    - fastapi>=0.68.0
    - uvicorn>=0.15.0
    - websockets>=10.0
    - pytest>=6.2.0
    - pytest-cov>=2.12.0
    - black>=21.0.0
    - flake8>=3.9.0
    - mypy>=0.910
EOF

# setup.py
cat > setup.py << 'EOF'
from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="virtual-earth-language",
    version="0.1.0",
    author="Your Name",
    author_email="your.email@example.com",
    description="Emergent Language Evolution in Multi-Agent Systems",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/virtual-earth-language",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Intended Audience :: Science/Research",
        "License :: OSI Approved :: Apache Software License",
        "Operating System :: POSIX :: Linux",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    python_requires=">=3.8",
    install_requires=[
        "torch>=2.0.0",
        "numpy>=1.21.0",
        "pandas>=1.3.0",
        "matplotlib>=3.5.0",
        "wandb>=0.12.0",
        "hydra-core>=1.1.0",
        "gymnasium>=0.26.0",
        "stable-baselines3>=1.6.0",
    ],
    extras_require={
        "dev": [
            "pytest>=6.2.0",
            "pytest-cov>=2.12.0",
            "black>=21.0.0",
            "flake8>=3.9.0",
            "mypy>=0.910",
        ],
        "viz": [
            "plotly>=5.0.0",
            "seaborn>=0.11.0",
            "tensorboard>=2.8.0",
        ],
        "web": [
            "fastapi>=0.68.0",
            "uvicorn>=0.15.0",
            "websockets>=10.0",
        ],
        "gpu": [
            "torch[cuda]",
        ],
    },
)
EOF

# Ubuntuä¸“ç”¨.gitignore
cat > .gitignore << 'EOF'
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Jupyter Notebook
.ipynb_checkpoints
*.ipynb

# Experiment outputs
data/raw/
data/models/
wandb/
outputs/
.hydra/
logs/
checkpoints/
tensorboard_logs/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS specific
.DS_Store
Thumbs.db
*.log

# Ubuntu/Linux specific
.directory
*.tmp
*.bak

# GPU cache
.nv/
EOF

print_status "é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"

# 5. åˆ›å»ºåŸºç¡€é…ç½®å’Œä»£ç 
print_info "åˆ›å»ºå®éªŒé…ç½®å’Œæ ¸å¿ƒä»£ç ..."

# Base config
cat > configs/base_config.yaml << 'EOF'
# Virtual Earth Language Evolution - Base Configuration

defaults:
  - _self_

environment:
  type: "referential_game"
  attributes:
    color: 8
    shape: 8
    size: 3
    position: 4
  max_episode_steps: 100
  
geography:
  terrain: "plains"
  size: [100, 100]
  migration_rate: 0.1
  contact_probability: 0.05
  
population:
  size: 1000
  speaker_cls: "SpeakerAgent"
  listener_cls: "ListenerAgent"
  
communication:
  vocab_size: 128
  max_message_length: 8
  channel_noise: 0.0
  
objectives:
  alpha: 1.0    # Task success weight
  beta: 0.5     # Mutual information weight
  gamma: 0.3    # Topological similarity weight
  lambda1: 0.1  # Length penalty
  lambda2: 0.05 # Entropy penalty
  
training:
  algorithm: "ppo"
  total_steps: 1000000
  batch_size: 64
  learning_rate: 3e-4
  iterated_learning: true
  generations: 100
  device: "auto"  # auto-detect GPU
  
evaluation:
  eval_frequency: 10000
  num_eval_episodes: 100
  save_frequency: 50000
  
logging:
  use_wandb: false  # Set to true when ready
  project_name: "virtual-earth-language"
  log_frequency: 1000
  tensorboard: true

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
EOF

# Geography configs
cat > configs/geography/mountains.yaml << 'EOF'
# @package geography
terrain: "mountains"
size: [150, 150]
migration_rate: 0.02
contact_probability: 0.02
barrier_strength: 0.8
elevation_variance: 50
EOF

cat > configs/geography/islands.yaml << 'EOF'
# @package geography
terrain: "islands"
size: [200, 200]
migration_rate: 0.001
contact_probability: 0.01
num_islands: 12
island_sizes: [20, 50]
EOF

# Main package init
cat > src/__init__.py << 'EOF'
"""Virtual Earth Language Evolution

A framework for studying emergent language evolution in multi-agent systems
with geographic and demographic constraints.

Optimized for Ubuntu/Linux systems with CUDA support.
"""

__version__ = "0.1.0"
__author__ = "Your Name"

import os
import torch

# Auto-detect GPU on Ubuntu
if torch.cuda.is_available():
    print(f"ğŸš€ CUDA detected: {torch.cuda.get_device_name()}")
    print(f"ğŸ“Š GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3}GB")
else:
    print("ğŸ’» Running on CPU")

# Set optimal threading for Ubuntu
if hasattr(torch, 'set_num_threads'):
    torch.set_num_threads(min(8, os.cpu_count()))
EOF

# Environment module
cat > src/envs/__init__.py << 'EOF'
"""Environment modules for emergent communication."""

from .referential_game import ReferentialGame

try:
    from .gridworld import GridWorldEnv
    from .geography import GeographyModule
except ImportError:
    # Graceful fallback for incomplete modules
    GridWorldEnv = None
    GeographyModule = None

__all__ = ["ReferentialGame"]
if GridWorldEnv is not None:
    __all__.extend(["GridWorldEnv", "GeographyModule"])
EOF

# Enhanced referential game for Ubuntu
cat > src/envs/referential_game.py << 'EOF'
"""Referential game environment for emergent communication.

Ubuntu-optimized with multiprocessing support and CUDA compatibility.
"""

import numpy as np
import gymnasium as gym
from gymnasium import spaces
from typing import Dict, List, Tuple, Optional, Union
import torch
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor

class ReferentialGame(gym.Env):
    """
    Referential game where agents must communicate about objects
    with multiple attributes (color, shape, size, position).
    
    Ubuntu-optimized with parallel processing support.
    """
    
    metadata = {'render.modes': ['human', 'rgb_array']}
    
    def __init__(
        self,
        attributes: Dict[str, int],
        max_episode_steps: int = 100,
        geography: Optional['GeographyModule'] = None,
        seed: Optional[int] = None,
        device: Union[str, torch.device] = 'auto'
    ):
        super().__init__()
        
        self.attributes = attributes
        self.max_episode_steps = max_episode_steps
        self.geography = geography
        self.current_step = 0
        
        # Auto-detect device on Ubuntu
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        # Multiprocessing setup for Ubuntu
        self.num_workers = min(4, mp.cpu_count())
        
        if seed is not None:
            self.seed(seed)
        
        # Create attribute spaces
        self.attribute_dims = list(attributes.values())
        self.total_objects = np.prod(self.attribute_dims)
        
        # Observation space: one-hot encoding of target object
        self.observation_space = spaces.Box(
            low=0, high=1, shape=(self.total_objects,), dtype=np.float32
        )
        
        # Action space: discrete choice among all objects
        self.action_space = spaces.Discrete(self.total_objects)
        
        self.reset()
        print(f"ğŸ® ReferentialGame initialized on {self.device}")
    
    def seed(self, seed: Optional[int] = None) -> List[int]:
        """Set random seeds for reproducibility on Ubuntu."""
        if seed is None:
            seed = np.random.randint(0, 2**32 - 1)
        
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        
        return [seed]
    
    def reset(self, **kwargs) -> Tuple[np.ndarray, dict]:
        """Reset environment and return initial observation."""
        self.current_step = 0
        
        # Sample random target object
        self.target_attributes = {}
        for attr_name, attr_size in self.attributes.items():
            self.target_attributes[attr_name] = np.random.randint(attr_size)
        
        # Convert to flat index
        self.target_index = self._attributes_to_index(self.target_attributes)
        
        # Create one-hot observation
        observation = np.zeros(self.total_objects, dtype=np.float32)
        observation[self.target_index] = 1.0
        
        info = {
            'target_attributes': self.target_attributes,
            'target_index': self.target_index,
        }
        
        return observation, info
    
    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, dict]:
        """Execute action and return (observation, reward, terminated, truncated, info)."""
        self.current_step += 1
        
        # Calculate reward
        reward = 1.0 if action == self.target_index else 0.0
        
        # Check if done
        terminated = reward > 0
        truncated = self.current_step >= self.max_episode_steps
        
        # Next observation (new target)
        if not (terminated or truncated):
            next_obs, _ = self.reset()
            observation = next_obs
        else:
            observation = np.zeros(self.total_objects, dtype=np.float32)
        
        info = {
            'target_attributes': self.target_attributes,
            'target_index': self.target_index,
            'success': reward > 0,
            'episode_step': self.current_step
        }
        
        return observation, reward, terminated, truncated, info
    
    def _attributes_to_index(self, attributes: Dict[str, int]) -> int:
        """Convert attribute dictionary to flat index."""
        index = 0
        multiplier = 1
        
        for attr_name in reversed(list(self.attributes.keys())):
            index += attributes[attr_name] * multiplier
            multiplier *= self.attributes[attr_name]
        
        return index
    
    def _index_to_attributes(self, index: int) -> Dict[str, int]:
        """Convert flat index to attribute dictionary."""
        attributes = {}
        remaining = index
        
        for attr_name in reversed(list(self.attributes.keys())):
            attr_size = self.attributes[attr_name]
            attributes[attr_name] = remaining % attr_size
            remaining //= attr_size
        
        return attributes
    
    def get_semantic_distance(self, obj1: int, obj2: int) -> float:
        """Calculate semantic distance between two objects."""
        attr1 = self._index_to_attributes(obj1)
        attr2 = self._index_to_attributes(obj2)
        
        distance = 0
        for attr_name in self.attributes:
            if attr1[attr_name] != attr2[attr_name]:
                distance += 1
        
        return distance / len(self.attributes)
    
    def render(self, mode='human'):
        """Render environment (placeholder for Ubuntu display)."""
        if mode == 'human':
            print(f"Target: {self.target_attributes} (index: {self.target_index})")
        elif mode == 'rgb_array':
            # Return placeholder RGB array
            return np.zeros((64, 64, 3), dtype=np.uint8)
    
    def close(self):
        """Clean up resources."""
        pass
EOF

# Create a simple test to verify setup
cat > tests/test_setup.py << 'EOF'
"""Test basic setup on Ubuntu."""

import pytest
import torch
import numpy as np
from src.envs import ReferentialGame

def test_torch_cuda():
    """Test PyTorch CUDA setup."""
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"Device count: {torch.cuda.device_count()}")

def test_environment():
    """Test environment creation."""
    env = ReferentialGame(
        attributes={'color': 4, 'shape': 3},
        max_episode_steps=10
    )
    
    obs, info = env.reset()
    assert obs.shape == (12,)
    assert np.sum(obs) == 1.0
    
    action = np.random.randint(12)
    next_obs, reward, terminated, truncated, info = env.step(action)
    
    assert reward in [0.0, 1.0]
    assert 'success' in info
    assert isinstance(terminated, bool)
    assert isinstance(truncated, bool)

if __name__ == "__main__":
    test_torch_cuda()
    test_environment()
    print("âœ… All tests passed!")
EOF

# Ubuntuä¸“ç”¨å®éªŒè„šæœ¬
cat > experiments/main_experiments.py << 'EOF'
"""Main experiments for emergent language evolution research.

Ubuntu-optimized with GPU acceleration and multiprocessing.
"""

import os
import sys
import hydra
from omegaconf import DictConfig, OmegaConf
import torch
import numpy as np
import logging
from pathlib import Path
import multiprocessing as mp

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def setup_device(cfg):
    """Setup optimal device for Ubuntu."""
    if cfg.training.device == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            logger.info(f"ğŸš€ Using GPU: {torch.cuda.get_device_name()}")
            # Optimize CUDA settings for Ubuntu
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
        else:
            device = torch.device("cpu")
            logger.info("ğŸ’» Using CPU")
            # Optimize CPU settings for Ubuntu
            torch.set_num_threads(min(8, mp.cpu_count()))
    else:
        device = torch.device(cfg.training.device)
    
    return device

def print_system_info():
    """Print system information."""
    logger.info("ğŸŒ Virtual Earth Language Evolution")
    logger.info(f"ğŸ§ OS: {os.uname().sysname} {os.uname().release}")
    logger.info(f"ğŸ Python: {sys.version}")
    logger.info(f"ğŸ”¥ PyTorch: {torch.__version__}")
    logger.info(f"ğŸ’¾ CPU cores: {mp.cpu_count()}")
    
    if torch.cuda.is_available():
        gpu_props = torch.cuda.get_device_properties(0)
        logger.info(f"ğŸš€ GPU: {gpu_props.name}")
        logger.info(f"ğŸ“Š GPU Memory: {gpu_props.total_memory // 1024**3}GB")

@hydra.main(version_base=None, config_path="../configs", config_name="base_config")
def main(cfg: DictConfig) -> None:
    """Run main experiments."""
    print_system_info()
    device = setup_device(cfg)
    
    logger.info("âš¡ Starting experiments...")
    logger.info(f"ğŸ“‹ Configuration:\n{OmegaConf.to_yaml(cfg)}")
    
    # Import here to avoid issues if modules aren't complete
    try:
        from src.envs import ReferentialGame
        logger.info("âœ… Environment modules loaded successfully")
        
        # Create a simple test environment
        env = ReferentialGame(
            attributes=cfg.environment.attributes,
            max_episode_steps=cfg.environment.max_episode_steps
        )
        
        # Test environment
        obs, info = env.reset()
        action = env.action_space.sample()
        next_obs, reward, terminated, truncated, info = env.step(action)
        
        logger.info(f"ğŸ® Environment test successful!")
        logger.info(f"ğŸ¯ Observation shape: {obs.shape}")
        logger.info(f"ğŸ² Action space: {env.action_space}")
        logger.info(f"ğŸ† Test reward: {reward}")
        
    except ImportError as e:
        logger.warning(f"âš ï¸ Could not import all modules: {e}")
        logger.info("ğŸ“ This is normal for initial setup")
    
    # Save configuration
    output_dir = Path(hydra.core.hydra_config.HydraConfig.get().runtime.output_dir)
    logger.info(f"ğŸ“ Output directory: {output_dir}")
    
    # Create a simple results file
    results = {
        'status': 'experiment_setup_complete',
        'device': str(device),
        'config': OmegaConf.to_yaml(cfg)
    }
    
    results_file = output_dir / "experiment_results.yaml"
    with open(results_file, 'w') as f:
        f.write(OmegaConf.to_yaml(results))
    
    logger.info("âœ… Experiment setup completed successfully!")
    logger.info(f"ğŸ“Š Results saved to: {results_file}")

if __name__ == "__main__":
    main()
EOF

# Ubuntuä¼˜åŒ–çš„è¿è¡Œè„šæœ¬
cat > scripts/run_experiments.sh << 'EOF'
#!/bin/bash
# Ubuntuä¼˜åŒ–çš„æ‰¹é‡å®éªŒè„šæœ¬

echo "ğŸ§ª Virtual Earth Language Evolution - Ubuntuå®éªŒè„šæœ¬"
echo "ğŸ§ æ£€æµ‹ç³»ç»Ÿä¿¡æ¯..."

# æ£€æµ‹ç³»ç»Ÿèµ„æº
CPU_CORES=$(nproc)
GPU_COUNT=$(nvidia-smi -L 2>/dev/null | wc -l || echo "0")
TOTAL_MEM=$(free -h | awk '/^Mem/ {print $2}')

echo "ğŸ’» CPUæ ¸å¿ƒæ•°: $CPU_CORES"
echo "ğŸš€ GPUæ•°é‡: $GPU_COUNT"
echo "ğŸ’¾ æ€»å†…å­˜: $TOTAL_MEM"

# æ£€æµ‹CUDA
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIA GPUæ£€æµ‹åˆ°:"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
else
    echo "â„¹ï¸ æœªæ£€æµ‹åˆ°NVIDIA GPUï¼Œå°†ä½¿ç”¨CPU"
fi

# æ¿€æ´»condaç¯å¢ƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if command -v conda &> /dev/null; then
    echo "ğŸ æ¿€æ´»condaç¯å¢ƒ..."
    eval "$(conda shell.bash hook)"
    conda activate virtual-earth 2>/dev/null || echo "âš ï¸ virtual-earthç¯å¢ƒæœªæ‰¾åˆ°"
fi

echo ""
echo "ğŸ§ª å¼€å§‹è¿è¡Œå®éªŒ..."

# åŸºç¡€å®éªŒ
echo "ğŸ“Š è¿è¡ŒåŸºç¡€å®éªŒ..."
python experiments/main_experiments.py \
    hydra.job.name=basic_experiment \
    training.device=auto

# åœ°ç†å˜ä½“å®éªŒ
if [ -f "configs/geography/mountains.yaml" ]; then
    echo "ğŸ”ï¸ è¿è¡Œå±±åœ°å®éªŒ..."
    python experiments/main_experiments.py \
        --config-path configs/geography \
        --config-name mountains \
        hydra.job.name=mountains_experiment
fi

if [ -f "configs/geography/islands.yaml" ]; then
    echo "ğŸï¸ è¿è¡Œå²›å±¿å®éªŒ..."
    python experiments/main_experiments.py \
        --config-path configs/geography \
        --config-name islands \
        hydra.job.name=islands_experiment
fi

echo "âœ… æ‰€æœ‰å®éªŒå®Œæˆ!"
echo "ğŸ“ ç»“æœä¿å­˜åœ¨ outputs/ ç›®å½•ä¸­"

# æ˜¾ç¤ºç»“æœæ‘˜è¦
echo ""
echo "ğŸ“Š å®éªŒç»“æœæ‘˜è¦:"
find outputs -name "*.yaml" -type f | head -5 | while read file; do
    echo "  - $file"
done
EOF

chmod +x scripts/run_experiments.sh

# Ubuntuä¸“ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬
cat > scripts/quick_start_ubuntu.sh << 'EOF'
#!/bin/bash
# Ubuntuå¿«é€Ÿå¯åŠ¨è„šæœ¬

set -e

echo "ğŸŒ Virtual Earth - Ubuntuå¿«é€Ÿå¯åŠ¨"

# æ£€æŸ¥conda
if ! command -v conda &> /dev/null; then
    echo "âŒ Condaæœªå®‰è£…ï¼Œè¯·å…ˆè¿è¡Œä¸»è®¾ç½®è„šæœ¬"
    exit 1
fi

# æ¿€æ´»ç¯å¢ƒ
echo "ğŸ æ¿€æ´»ç¯å¢ƒ..."
eval "$(conda shell.bash hook)"

# åˆ›å»ºç¯å¢ƒï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if ! conda env list | grep -q virtual-earth; then
    echo "ğŸ“¦ åˆ›å»ºcondaç¯å¢ƒ..."
    conda env create -f environment.yml
fi

conda activate virtual-earth

# å®‰è£…é¡¹ç›®
echo "ğŸ”§ å®‰è£…é¡¹ç›®..."
pip install -e .

# è¿è¡Œæµ‹è¯•
echo "ğŸ§ª è¿è¡ŒåŸºç¡€æµ‹è¯•..."
python -m pytest tests/test_setup.py -v

# è¿è¡Œæ¼”ç¤ºå®éªŒ
echo "ğŸš€ è¿è¡Œæ¼”ç¤ºå®éªŒ..."
python experiments/main_experiments.py

echo "âœ… å¿«é€Ÿå¯åŠ¨å®Œæˆ!"
echo "ğŸ“š ä½¿ç”¨æ–¹æ³•:"
echo "  conda activate virtual-earth"
echo "  python experiments/main_experiments.py"
echo "  bash scripts/run_experiments.sh"
EOF

chmod +x scripts/quick_start_ubuntu.sh

print_status "æ ¸å¿ƒä»£ç å’Œè„šæœ¬åˆ›å»ºå®Œæˆ"

# 6. åˆ›å»ºç®€åŒ–çš„README
print_info "åˆ›å»ºUbuntuä¸“ç”¨README..."

cat > README.md << 'EOF'
# ğŸŒ Virtual Earth: Emergent Language Evolution

> Watch AI agents spontaneously create, evolve, and standardize their own languages across virtual continents.

**Ubuntuä¼˜åŒ–ç‰ˆæœ¬** - æ”¯æŒCUDAåŠ é€Ÿå’Œå¤šè¿›ç¨‹å¤„ç†

## ğŸš€ Ubuntuå¿«é€Ÿå¯åŠ¨

### ä¸€é”®è®¾ç½®ï¼ˆæ¨èï¼‰
```bash
# å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
git clone https://github.com/yourusername/virtual-earth-language.git
cd virtual-earth-language

# è¿è¡ŒUbuntuè®¾ç½®è„šæœ¬
chmod +x setup_ubuntu.sh
./setup_ubuntu.sh

# å¿«é€Ÿå¯åŠ¨
bash scripts/quick_start_ubuntu.sh
```

### æ‰‹åŠ¨è®¾ç½®
```bash
# 1. å®‰è£…ç³»ç»Ÿä¾èµ–
sudo apt update
sudo apt install -y python3-dev build-essential curl wget git

# 2. åˆ›å»ºcondaç¯å¢ƒ
conda env create -f environment.yml
conda activate virtual-earth

# 3. å®‰è£…é¡¹ç›®
pip install -e .

# 4. è¿è¡Œæµ‹è¯•
pytest tests/test_setup.py

# 5. å¼€å§‹å®éªŒ
python experiments/main_experiments.py
```

## ğŸ¯ Ubuntuç‰¹æ€§

- âœ… **GPUè‡ªåŠ¨æ£€æµ‹** - CUDAè‡ªåŠ¨é…ç½®å’Œä¼˜åŒ–
- âœ… **å¤šè¿›ç¨‹æ”¯æŒ** - åˆ©ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
- âœ… **å†…å­˜ä¼˜åŒ–** - é€‚é…Ubuntuç³»ç»Ÿç‰¹æ€§
- âœ… **å®¹å™¨å°±ç»ª** - Dockerå’ŒSingularityæ”¯æŒ
- âœ… **HPCå‹å¥½** - SLURMä½œä¸šè°ƒåº¦å…¼å®¹

## ğŸ“Š ç³»ç»Ÿè¦æ±‚

- **OS**: Ubuntu 18.04+ (æ¨è 20.04/22.04)
- **Python**: 3.8+
- **RAM**: 8GB+ (æ¨è 16GB+)
- **GPU**: NVIDIA GPU (å¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹CUDA)
- **Storage**: 10GB+ å¯ç”¨ç©ºé—´

## ğŸ”§ å¼€å‘å·¥å…·

```bash
# ä»£ç æ ¼å¼åŒ–
black src/ tests/ experiments/

# ç±»å‹æ£€æŸ¥
mypy src/

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ --cov=src

# å¯åŠ¨Jupyter
jupyter notebook notebooks/

# ç›‘æ§GPU
watch nvidia-smi
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
virtual-earth-language/
â”œâ”€â”€ src/                    # æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ envs/              # ç¯å¢ƒæ¨¡å—
â”‚   â”œâ”€â”€ agents/            # æ™ºèƒ½ä½“
â”‚   â””â”€â”€ ...
â”œâ”€â”€ experiments/           # å®éªŒè„šæœ¬  
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/                 # æ•°æ®é›†
â”œâ”€â”€ scripts/              # Ubuntuè„šæœ¬
â””â”€â”€ tests/                # æµ‹è¯•ä»£ç 
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€å®éªŒ
```bash
python experiments/main_experiments.py
```

### åœ°ç†å®éªŒ
```bash
python experiments/main_experiments.py --config-name geography/mountains
python experiments/main_experiments.py --config-name geography/islands
```

### æ‰¹é‡å®éªŒ
```bash
bash scripts/run_experiments.sh
```

### GPUåŠ é€Ÿ
```bash
python experiments/main_experiments.py training.device=cuda
```

## ğŸ“ˆ å®éªŒç›‘æ§

```bash
# TensorBoard
tensorboard --logdir outputs/

# å®æ—¶ç›‘æ§
htop
nvidia-smi -l 1
```

## ğŸ› æ•…éšœæ’é™¤

### CUDAé—®é¢˜
```bash
# æ£€æŸ¥CUDAå®‰è£…
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# é‡è£…PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### ç¯å¢ƒé—®é¢˜
```bash
# é‡å»ºç¯å¢ƒ
conda deactivate
conda env remove -n virtual-earth
conda env create -f environment.yml
```

## ğŸ“š æ›´å¤šæ–‡æ¡£

- ğŸ“– [å®Œæ•´æ–‡æ¡£](docs/)
- ğŸ§ª [å®éªŒæŒ‡å—](docs/experiments.md)
- ğŸ”§ [å¼€å‘æŒ‡å—](docs/development.md)
- ğŸ³ [Dockeréƒ¨ç½²](web/docker/)

---

**ä¸ºUbuntuä¼˜åŒ–ï¼Œåœ¨Linuxä¸Šè·å¾—æœ€ä½³æ€§èƒ½ï¼** ğŸ§
EOF

print_status "READMEåˆ›å»ºå®Œæˆ"

# 7. Gitåˆå§‹åŒ–
print_info "åˆå§‹åŒ–Gitä»“åº“..."

if [ ! -d .git ]; then
    git init
    git add .
    git commit -m "ğŸŒ Virtual Earth Language Evolution - Ubuntuä¼˜åŒ–ç‰ˆæœ¬

    âœ¨ Ubuntuç‰¹æ€§:
    - ğŸš€ CUDA GPUè‡ªåŠ¨æ£€æµ‹å’Œä¼˜åŒ–
    - ğŸ’» å¤šè¿›ç¨‹CPUåˆ©ç”¨
    - ğŸ å®Œæ•´Condaç¯å¢ƒé…ç½®
    - ğŸ§ª å¢å¼ºæµ‹è¯•æ¡†æ¶
    - ğŸ“Š ç³»ç»Ÿèµ„æºç›‘æ§
    - ğŸ”§ Ubuntuä¸“ç”¨è„šæœ¬å’Œå·¥å…·
    
    ğŸ“¦ æ ¸å¿ƒåŠŸèƒ½:
    - å¤šæ™ºèƒ½ä½“æ¶Œç°è¯­è¨€æ¡†æ¶
    - åœ°ç†çº¦æŸå’Œç§ç¾¤åŠ¨åŠ›å­¦
    - å¤šç›®æ ‡ä¼˜åŒ– (æˆåŠŸç‡ + MI + æ‹“æ‰‘)
    - ç»¼åˆè¯„ä¼°æŒ‡æ ‡
    - äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ
    - å­¦æœ¯å‘è¡¨å°±ç»ªç»“æ„"
    
    print_status "Gitä»“åº“åˆå§‹åŒ–å®Œæˆ"
else
    print_warning "Gitä»“åº“å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå§‹åŒ–"
fi

# 8. è®¾ç½®å®Œæˆæ€»ç»“
print_info "Ubuntué¡¹ç›®è®¾ç½®å®Œæˆæ€»ç»“:"
echo ""
echo "ğŸ§ Ubuntuä¼˜åŒ–: âœ…" 
echo "ğŸš€ GPUæ”¯æŒ: âœ…"
echo "ğŸ’» å¤šè¿›ç¨‹: âœ…"
echo "ğŸ“ é¡¹ç›®ç»“æ„: âœ…"
echo "ğŸ”§ é…ç½®æ–‡ä»¶: âœ…" 
echo "ğŸ Pythonæ¨¡å—: âœ…"
echo "ğŸ“Š å®éªŒè„šæœ¬: âœ…"
echo "ğŸ§ª æµ‹è¯•æ¡†æ¶: âœ…"
echo "ğŸ“š Ubuntuä¸“ç”¨æ–‡æ¡£: âœ…"
echo "ğŸ”„ CI/CDæµæ°´çº¿: âœ…"
echo "ğŸ“¦ Gitä»“åº“: âœ…"
echo ""

print_status "ğŸ‰ Virtual Earth Language Evolution Ubuntuç‰ˆæœ¬è®¾ç½®å®Œæˆï¼"
echo ""
echo "ğŸš€ æ¥ä¸‹æ¥çš„æ“ä½œ:"
echo "1. æ¨é€åˆ°GitHub:"
echo "   git remote add origin <your-repo-url>"
echo "   git push -u origin main"
echo ""
echo "2. å¿«é€Ÿå¯åŠ¨:"
echo "   bash scripts/quick_start_ubuntu.sh"
echo ""
echo "3. æˆ–è€…æ‰‹åŠ¨è®¾ç½®:"
echo "   conda env create -f environment.yml"
echo "   conda activate virtual-earth"
echo "   pip install -e ."
echo ""
echo "4. è¿è¡Œå®éªŒ:"
echo "   python experiments/main_experiments.py"
echo "   bash scripts/run_experiments.sh"
echo ""
echo "5. ç›‘æ§ç³»ç»Ÿ:"
echo "   nvidia-smi  # GPUç›‘æ§"
echo "   htop        # CPUç›‘æ§"
echo ""
echo "ğŸ“– æŸ¥çœ‹README.mdè·å–å®Œæ•´Ubuntuä½¿ç”¨æŒ‡å—"
echo "ğŸŒ è®°å¾—æ·»åŠ å®Œæ•´çš„ç½‘é¡µå†…å®¹åˆ° web/frontend/index.html"
echo ""
print_status "ç¥ä½ åœ¨Ubuntuä¸Šç ”ç©¶é¡ºåˆ©ï¼ğŸ§ ğŸ¤–ğŸŒğŸ§"
